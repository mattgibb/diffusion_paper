%!TEX root = ../diffusion_paper.tex
\section{Discussion and Conclusions} % (fold)
\label{sec:discussion_and_conclusions}
  We have invented a robust and mathematically elegant method of resolving volumes from noisy 2-dimensional image slices, transferring transformational information between neighbouring slices. It excels any current technique in the literature at providing smooth, continuous volumes, whilst preserving underlying geometry. Further, its iterative nature confers to it a resilience to the trap of local minima, to registration failures and to outliers, which is unmatched by contemporary methods; even when the cost function of a registration is spiky, and results of a single run are sensitive to initialisation, the TDS algorithm provides multiple opportunities to escape local basins in the cost function, having shifted the cost landscape each time. Contrastingly in the case of banana registration, the displacement from one unsuccessful registration is propagated to \emph{every} subsequent slice in the volume.
  
  One might reasonably consider, as an alternative implementation, the registration of more than just the nearest neighbours at each iteration, but the \emph{k}-nearest neighbours, followed by the application of some (binomial) weighted mean of the results:
  \begin{equation}
    \mathbf{\Delta T}_i^{n,n+1} = \sum_{j=-k}^k \binom{2k}{j+k}\alpha \cdot \mathbf{\Delta T}_{i,i+j}^n,
  \end{equation}
  where we define the sum operator $\sum$ as
  \begin{equation}
    \sum_{i=0}^n \mathbf{T}_i = \mathbf{T}_0 \oplus \mathbf{T}_1 \oplus \ldots \oplus \mathbf{T}_n.
  \end{equation}
  Indeed, in 1-dimensional diffusion, $n$ iterations of nearest neighbour diffusion (where $k=1$) is equivalent to a single binomial iteration across a larger neighbourhood ($k=n$). There are three reasons why this approach is suboptimal. Firstly, inaccurate or erroneous registrations --- most likely to occur in the earliest stages with the most noise --- are given fewer chances to be mitigated by later iterations. Equivalently from another perspective, more registrations are performed under higher levels of perturbation than necessary. Secondly, the further away two histological slices are from each other within the real tissue volume, the more different they appear, and thus a successful registration between them is less likely. Thirdly, no computational time is saved, as the same total number of slice-to-slice registrations must be performed for a given level of smoothing. In fact, total computation is likely to be extended, as the more challenging registrations that are introduced will take longer to reach an optimum.
  
  As was mentioned at the end of Section~\ref{ssub:formulating_the_transform_operators}, this diffusion technique could be extended easily to more complex transforms, as long as that set of transformations form a Lie group. Diffeomorphic transformations fall under this category, and their differentiable and invertible properties are exploited to similar ends in the literature \cite{Avants2006}. Consistent B-splines may also be constrained to be quasi-invertible \cite{Arganda-Carreras2010}. Many transforms commonly used in registration, such as b-spline and other piecewise transforms, are excluded from this classification. In practice, the markedly lax constraint for improvement --- that the algorithm must simply  move each slice somewhat closer to its neighbours --- coupled with the fact that all transforms approximate a Lie group in the small limit, mean that a trivial linear interpolation of any transform's parameters will lead to reliable and geometrically faithful smoothing for noise levels significantly smaller than the scale of the registration.
    
	There is a tradeoff to be made when deciding upon a value for the diffusion constant $\alpha$. The greater $\alpha$, the faster and more computationally cheaply the high frequency random noise is damped. But when $\alpha$ approaches 0.5, unstable oscillations start to appear as slices move almost all the way toward the average of their neighbours. In all of the results presented in this paper, $\alpha$ is set to $0.4$.
  
  % WHAT WE ARE USING IS ESSENTIALLY A FORWARD EULER SCHEME, THERE MIGHT BE OTHER SCHEMES THAT ARE MORE EFFICIENT, BUT THE FACT THAT WE ARE WORKING WITH TRANSFORMS MAKES IT MORE DIFFICULT TO ADAPT THESE SCHEMES TO OUR CASE, AND SO WE HAVEN'T INVESTIGATED THESE SCHEMES FOR THIS PAPER.

  One of the main decisions when enhancing volumes with TDS is how many iterations should be applied. If the amplitude of the noise frequency spectrum is distributed higher and away from the true underlying geometrical spectrum, then after an initial few iterations of successful noise reduction, the volume will remain largely unchanged in a wide optimal window, whilst a basin of near-zero amplitude frequencies are being damped. Eventually of course, the true low-frequency signal will begin damping, leading to undesired banana-like effects. In practice, it is often simple to detect this window by comparing the output volumes of a range of iteration numbers, looking for the smallest changes in the appearance of cross-sections or segmented contours.
  
  Choosing the optimal number of iterations becomes more complex when preserving genuinely acute image curvature. Just as in the case of 1-dimensional diffusion, true underlying high-frequency signal will be smoothed indiscriminately along with noise. For example, any sharp variation in cardiac geometry expressed across fewer than $\sim$5 slices will be smoothed significantly after 20 iterations. Where the banana problem erroneously symmetrises a geometry, TDS can erroneously symmetrise the \emph{curvature} of a geometry, if applied too heavily. Anisotropic TDS could well be employed to dampen the diffusive coefficient $\alpha$ adaptively, in regions of strong variation where curvature must be preserved. The anisotropy might be based upon some scalar measure of the magnitude of the transforms between slices, upon the final metric values of the individual registrations, or upon the images or pairs of images themselves. Anisotropic diffusion is used widely in order to clear up noise in the intensity of images, and ~\cite{Arsigny2005} apply anisotropic diffusion to tensor images through a log-Euclidian framework.
  
  Boundary conditions at edge slices should be chosen based upon the error in the the edge slice positioning, and upon an estimate of the symmetry at the boundary. Where the error in the edge slice position is thought to be larger than the transformational gradient near the boundary, zero-Neumann discrete boundary conditions can be implemented; a ghost slice that perfectly matches the edge slice with the identity transform is used, along with its single neighbour, to calculate its diffusion at each iteration. This of course introduces banana-like straightening effects near the boundary, as the influx of contributions from the identity penetrate the volume. Alternatively, if the gradient of transformation can be estimated near the boundary, for example via the inverse transforms of the banana registration of the reference images, then non-zero Neumann conditions should be used. Where the positions of boundary slices are considered accurate, Dirichlet-like boundary conditions can lock them in place. Of course, if appropriate, a combination of Neumann and Dirichlet boundary conditions can be implemented.
  
  Going forward, log-Euclidean statistics could be used for averaging pair-wise registrations between 3D data sets, for example between a set of rat hearts. A single representative map could then be developed from the whole dataset, and statistics such as anatomical variation extracted from it. The TDS framework could also be used to smooth out jolting or high-frequency transformational noise in 4D time-series datasets, whilst maintaining the overall positioning of features in space.  
% section discussion_and_conclusions (end)
